{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "PY0101ES-5.2_API_2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4GIZyf9g5Q"
      },
      "source": [
        "<a href=\"https://cognitiveclass.ai/\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/PY0101EN/Ad/CCLog.png\" width=\"200\" align=\"center\">\n",
        "</a>\n",
        "\n",
        "<h1 align=\"center\"><font size=\"5\"><b>Interfaz de programación de aplicaciones</b></font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjPcGZ7K9g5k"
      },
      "source": [
        "<p>En este cuaderno aprenderás a convertir un archivo de audio hablado en inglés a texto usando una API de Voz a Texto. Después traducirás la versión en inglés al español usando una API para traducir. <b>Observación:</b> Debes obtener las API Keys para completar el laboratorio.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra0yXGfh9g5m"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "<h2>Tabla de Contenido</h2>\n",
        "<ul>\n",
        "    <li><a href=\"#ref0\">Convertir Voz a Texto</a></li>\n",
        "    <li><a href=\"#ref1\">Traductor de Idiomas</a></li>\n",
        "    <li><a href=\"#ref2\">Ejercicios</a></li>\n",
        "</ul>\n",
        "<br>\n",
        "<p>Tiempo Estimado: <strong>25 min</strong></p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56jiWh_V9g5n",
        "outputId": "d525453f-9b0f-4a24-bd93-fe864ffa5053"
      },
      "source": [
        "# Necesitarás la siguiente librería\n",
        "!pip install ibm_watson wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ibm_watson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/2a/d91c8a5012d9b8973ebfcfe234b539dffd263b2fc729c92ff214bcc999a9/ibm-watson-5.2.2.tar.gz (407kB)\n",
            "\r\u001b[K     |▉                               | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 19.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 10.3MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 286kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 296kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 307kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 317kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 327kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 337kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 348kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 358kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 368kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 378kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 389kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 399kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409kB 7.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.8.1)\n",
            "Collecting websocket-client==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5f/3c211d168b2e9f9342cfb53bcfc26aab0eac63b998015e7af7bcae66119d/websocket_client-1.1.0-py2.py3-none-any.whl (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.23.0)\n",
            "Collecting ibm-cloud-sdk-core==3.*,>=3.3.6\n",
            "  Downloading https://files.pythonhosted.org/packages/99/55/ece4d000ca41c052c7331a0d14150e9c9c15e4f65943036cfff3bcd14cc7/ibm-cloud-sdk-core-3.10.0.tar.gz\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->ibm_watson) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (1.24.3)\n",
            "Collecting PyJWT<3.0.0,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\n",
            "Building wheels for collected packages: ibm-watson\n",
            "  Building wheel for ibm-watson (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-watson: filename=ibm_watson-5.2.2-cp37-none-any.whl size=403389 sha256=f8610686c944bd01d60da45d0e620cd0dffa405776d34e02be8259f0478d6815\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/48/97/e75b6c52cadfde48732a1047e78b3203845201c3f07ee432ca\n",
            "Successfully built ibm-watson\n",
            "Building wheels for collected packages: wget, ibm-cloud-sdk-core\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=8a33cf751863e0a24b77bd7530aea528459b4808f5c641ce7b2064b29b7845bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.10.0-cp37-none-any.whl size=60922 sha256=ff3ff7d30b18e7198e43cd31c09030f58f9604bc9f59144ab4b7d87659b4a2c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/4e/48/b02ad6dc75235fc4c0742d4e99571fe7d729e60bf365105be4\n",
            "Successfully built wget ibm-cloud-sdk-core\n",
            "Installing collected packages: websocket-client, PyJWT, ibm-cloud-sdk-core, ibm-watson, wget\n",
            "Successfully installed PyJWT-2.1.0 ibm-cloud-sdk-core-3.10.0 ibm-watson-5.2.2 websocket-client-1.1.0 wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoNYJhhO9g5q"
      },
      "source": [
        "<h2 id=\"ref0\">Convertir Voz a Texto</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl5n0G719g5s"
      },
      "source": [
        "<p>Primero vamos a importar <code>SpeechToTextV1</code> desde <code>ibm_watson</code>. Para mas información sobre la API, por favor visita este <a href=\"https://cloud.ibm.com/apidocs/speech-to-text?code=python\">enlace</a></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mLLYYSmg9g5t"
      },
      "source": [
        "from ibm_watson import SpeechToTextV1 \n",
        "import json\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djkXGTwa9g5u"
      },
      "source": [
        "<p>El endpoint del servicio esta basado en la ubicación de la instancia, nosotros guardaremos la información en la URL. Para averiguar cual URL usar, revisa los permisos del servicio.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQNkdOO_9g5v"
      },
      "source": [
        "url_s2t = \"https://stream.watsonplatform.net/speech-to-text/api\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zag2Z-Xn9g5z"
      },
      "source": [
        "<p>Necesitas una API KEY, puedes obtenerla <a href=\"https://cloud.ibm.com/resources\">Aquí </a>.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ynBNZsj49g50"
      },
      "source": [
        "iam_apikey_s2t = \"pB5bEm0Ssy7tMCy2Z9XEgSnNB0QIWugbh5t0Rr8n_ake\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkIlEKyl9g50"
      },
      "source": [
        "<p>Creas un <a href=\"http://watson-developer-cloud.github.io/python-sdk/v0.25.0/apis/watson_developer_cloud.speech_to_text_v1.html\">Objeto Speech To Text Adapter</a>. Los parámetros serán el endpoint de la API KEY</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azc65Y4C9g51",
        "outputId": "32d05f03-f363-4e33-9b56-69b78fab5c59"
      },
      "source": [
        "authenticator = IAMAuthenticator(iam_apikey_s2t)\n",
        "s2t = SpeechToTextV1(authenticator=authenticator)\n",
        "s2t.set_service_url(url_s2t)\n",
        "s2t"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter at 0x7f04b2186650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sx7Vy879g53"
      },
      "source": [
        "<p>Vamos a descargar el archivo de audio que usaremos para convertir en texto.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BaT1dRQ9g54",
        "outputId": "8185e075-7d92-4991-ec56-22ec37617856"
      },
      "source": [
        "!wget -O PolynomialRegressionandPipelines.mp3  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/PY0101EN/labs/PolynomialRegressionandPipelines.mp3\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-07 21:53:49--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/PY0101EN/labs/PolynomialRegressionandPipelines.mp3\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4234179 (4.0M) [audio/mpeg]\n",
            "Saving to: ‘PolynomialRegressionandPipelines.mp3’\n",
            "\n",
            "PolynomialRegressio 100%[===================>]   4.04M  19.8MB/s    in 0.2s    \n",
            "\n",
            "2021-07-07 21:53:50 (19.8 MB/s) - ‘PolynomialRegressionandPipelines.mp3’ saved [4234179/4234179]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKO8NlZx9g55"
      },
      "source": [
        "<p>Tenemos la ruta al archivo wav que queremos convertir en texto</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "te75v4fB9g56"
      },
      "source": [
        "filename='PolynomialRegressionandPipelines.mp3'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHf6O3IY9g57"
      },
      "source": [
        "<p>Creamos el objeto <code>wav</code> con el archivo wav usando <code>open</code> ; configuramos <code>mode</code> a “rb”, esto es parecido al modo lectura y asegura que el archivo esta en modo binario. Usamos el método <code>recognize</code> que regresa el texto reconocido. El parámetro audio es el objeto <code>wav</code>, el parámetro <code>content_type</code> es el formato del archivo de audio.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "sFc3c0zc9g57"
      },
      "source": [
        "with open(filename, mode=\"rb\")  as wav:\n",
        "    response = s2t.recognize(audio=wav, content_type='audio/mp3')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ouo5jQWb9g58"
      },
      "source": [
        "<p>El atributo “result” contiene un diccionario que incluye la traducción:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ze6Fmm9g58",
        "outputId": "3095f695-5556-480a-bce6-721e2a7c9ff1"
      },
      "source": [
        "response.result"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'result_index': 0,\n",
              " 'results': [{'alternatives': [{'confidence': 0.94,\n",
              "     'transcript': 'in this video we will cover polynomial regression and pipelines '}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.9,\n",
              "     'transcript': \"what do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code \"}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.95,\n",
              "     'transcript': \"polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function \"}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.95,\n",
              "     'transcript': 'the model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation '}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.91,\n",
              "     'transcript': \"there also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear \"}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.89,\n",
              "     'transcript': \"let's look at an example from our data we generate a polynomial regression model \"}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.92,\n",
              "     'transcript': 'in python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression '}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.9,\n",
              "     'transcript': \"negative one point five five seven X. one cute plus two hundred four point eight X. one squared plus eight thousand nine hundred sixty five X. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example \"}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.9,\n",
              "     'transcript': 'consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that I mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate X. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline '}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.89,\n",
              "     'transcript': 'pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well '}],\n",
              "   'final': True},\n",
              "  {'alternatives': [{'confidence': 0.88,\n",
              "     'transcript': 'the method normalizes the data performs a polynomial transform then outputs a prediction '}],\n",
              "   'final': True}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "5NhV2YNT9g59",
        "outputId": "c74c3f24-404b-4674-d056-6690b2642cc3"
      },
      "source": [
        "from pandas.io.json import json_normalize\n",
        "\n",
        "json_normalize(response.result['results'],\"alternatives\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in this video we will cover polynomial regress...</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what do we do when a linear model is not the b...</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>polynomial regression is a special case of the...</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the model can be cubic which means the predict...</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>there also exists higher order polynomial regr...</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>let's look at an example from our data we gene...</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>in python we do this by using the poly fit fun...</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>negative one point five five seven X. one cute...</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>consider the feature shown here applying the m...</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pipeline sequentially perform a series of tran...</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>the method normalizes the data performs a poly...</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           transcript  confidence\n",
              "0   in this video we will cover polynomial regress...        0.94\n",
              "1   what do we do when a linear model is not the b...        0.90\n",
              "2   polynomial regression is a special case of the...        0.95\n",
              "3   the model can be cubic which means the predict...        0.95\n",
              "4   there also exists higher order polynomial regr...        0.91\n",
              "5   let's look at an example from our data we gene...        0.89\n",
              "6   in python we do this by using the poly fit fun...        0.92\n",
              "7   negative one point five five seven X. one cute...        0.90\n",
              "8   consider the feature shown here applying the m...        0.90\n",
              "9   pipeline sequentially perform a series of tran...        0.89\n",
              "10  the method normalizes the data performs a poly...        0.88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE-l_wg89g5-",
        "outputId": "004fe2e0-bfcf-42eb-8ab9-1bb9004b8a31"
      },
      "source": [
        "response"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x7f04b22263d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsdoqWFh9g5_"
      },
      "source": [
        "<p>Obtenemos el texto reconocido y los asignamos a la variable <code>recognized_text</code>:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWAM6XDo9g5_",
        "outputId": "30305dbe-f335-4ffa-f94c-94491a8cae3b"
      },
      "source": [
        "recognized_text=response.result['results'][0][\"alternatives\"][0][\"transcript\"]\n",
        "type(recognized_text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aumn6zm-9g6D"
      },
      "source": [
        "<h2 id=\"ref1\">Traductor de Idiomas</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmsdKjVa9g6E"
      },
      "source": [
        "<p>Primero importamos <code>LanguageTranslatorV3</code> desde ibm_watson. Para mas información sobre la API, por favor visita este <a href=\"https://cloud.ibm.com/apidocs/speech-to-text?code=python\">enlace</a></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp8xpG949g6F"
      },
      "source": [
        "from ibm_watson import LanguageTranslatorV3"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_0kJXyM9g6F"
      },
      "source": [
        "<p>El endpoint del servicio esta basado en la ubicación de la instancia, nosotros guardaremos la información en la URL. Para averiguar cual URL usar, revisa los permisos del servicio.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "hm3UBGpS9g6G"
      },
      "source": [
        "url_lt='https://api.us-south.language-translator.watson.cloud.ibm.com/instances/2a5a20ad-e47a-4d6a-ae56-b5bacf81f052'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQc2OVoW9g6G"
      },
      "source": [
        "<p>Necesitas una API KEY, puedes obtenerla <a href=\"https://cloud.ibm.com/resources\">Aquí </a>.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "GxUatlrC9g6G"
      },
      "source": [
        "apikey_lt='vxioghBPRqwxDrot9n0zQ23LLhPd8-_s5kZOoU9Wd-a8'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHXyrQML9g6H"
      },
      "source": [
        "<p>Las solicitudes a la API requieren un parámetro de la versión que tiene formato = YYYY-MM-DD. Este laboratorio trabaja con la versión actual de Language Translator, 2018-05-01</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "O84TOEcw9g6H"
      },
      "source": [
        "version_lt='2018-05-01'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfb6qAFY9g6I"
      },
      "source": [
        "<p>Creamos un objeto tipo Language Translator <code>language_translator</code>:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hYdF6hs9g6I",
        "outputId": "db0be8ba-fca1-4208-a6dc-4952c6abeb3f"
      },
      "source": [
        "authenticator = IAMAuthenticator(apikey_lt)\n",
        "language_translator = LanguageTranslatorV3(version=version_lt,authenticator=authenticator)\n",
        "language_translator.set_service_url(url_lt)\n",
        "language_translator"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ibm_watson.language_translator_v3.LanguageTranslatorV3 at 0x7f04b1c876d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7pPi0Qf9g6J"
      },
      "source": [
        "<p>Podemos obtener una lista del idioma que el servicio puede identificar. El método regresa un código que identifica al idioma. Por ejemplo Inglés (en) a Spanish (es) y el nombre de cada idioma.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "rirRBr-09g6J",
        "outputId": "0f1c99be-cea2-479b-d3cb-db6ea06561f5"
      },
      "source": [
        "from pandas.io.json import json_normalize\n",
        "\n",
        "json_normalize(language_translator.list_identifiable_languages().get_result(), \"languages\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>af</td>\n",
              "      <td>Afrikaans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>az</td>\n",
              "      <td>Azerbaijani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ba</td>\n",
              "      <td>Bashkir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>be</td>\n",
              "      <td>Belarusian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>uk</td>\n",
              "      <td>Ukrainian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>vi</td>\n",
              "      <td>Vietnamese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>zh</td>\n",
              "      <td>Simplified Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>zh-TW</td>\n",
              "      <td>Traditional Chinese</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   language                 name\n",
              "0        af            Afrikaans\n",
              "1        ar               Arabic\n",
              "2        az          Azerbaijani\n",
              "3        ba              Bashkir\n",
              "4        be           Belarusian\n",
              "..      ...                  ...\n",
              "71       uk            Ukrainian\n",
              "72       ur                 Urdu\n",
              "73       vi           Vietnamese\n",
              "74       zh   Simplified Chinese\n",
              "75    zh-TW  Traditional Chinese\n",
              "\n",
              "[76 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5qyMfJP9g6N"
      },
      "source": [
        "<p>Podemos usar le método <code>translate</code> para que traduzca el texto. El parámetro text será el texto. Model_id es el tipo de modelo que nos gustaría usar. En este caso, lo configuraremos para ‘en-es’ o Inglés a Español. Obtendremos un objeto tipo Detailed Response <code>translation_response</code>.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6yGM9Nd9g6Q",
        "outputId": "ac6f74f4-a9d9-495c-a2e0-83dd7f95cc63"
      },
      "source": [
        "translation_response = language_translator.translate(\\  \n",
        "    text=recognized_text, model_id='en-es')\n",
        "translation_response"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x7f04b1c488d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VbxMSDP9g6R"
      },
      "source": [
        "<p>El resultado es un diccionario.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8WA8lyg9g6U",
        "outputId": "a1cca5c6-0e6e-45e7-a594-0d7b9867bec8"
      },
      "source": [
        "translation=translation_response.get_result()\n",
        "translation"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'character_count': 64,\n",
              " 'translations': [{'translation': 'en este vídeo cubriremos la regresión polinómica y las tuberías '}],\n",
              " 'word_count': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0PiXYJF9g6V"
      },
      "source": [
        "<p>Podemos obtener la traducción como tipo cadena de la siguiente manera:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WBddIFgY9g6X",
        "outputId": "f5e72b7f-2a60-494a-b84f-0e2e98374684"
      },
      "source": [
        "spanish_translation =translation['translations'][0]['translation']\n",
        "spanish_translation "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'en este vídeo cubriremos la regresión polinómica y las tuberías '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4aZ-H7m9g6Y"
      },
      "source": [
        "<p>Podemos traducir de regreso al idioma inglés</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhGJLqj_9g6Y"
      },
      "source": [
        "translation_new = language_translator.translate(text=spanish_translation ,model_id='es-en').get_result()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bji9Wbjv9g6Z"
      },
      "source": [
        "<p>Podemos obtener la traducción como tipo cadena de la siguiente manera:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gb2IldVY9g6Z",
        "outputId": "85c3b05e-a590-43f9-bd1d-7ccccad48319"
      },
      "source": [
        "translation_eng=translation_new['translations'][0]['translation']\n",
        "translation_eng"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'in this video we will cover the polynomial regression and the pipes '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G9eWMBN9g6a"
      },
      "source": [
        "<p>Podemos traducirlo al idioma frances también:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7i-etV99g6a"
      },
      "source": [
        "French_translation=language_translator.translate(\n",
        "    text=translation_eng , model_id='en-fr').get_result()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vnMWaYmV9g6b",
        "outputId": "72dd7efc-d207-48bd-9e1a-140eb7f0e939"
      },
      "source": [
        "French_translation['translations'][0]['translation']"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dans cette vidéo nous couvrons la régression polynomiale et les tuyaux '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w8b2FOk9g6b"
      },
      "source": [
        "<h3>Traductor de Idiomas</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUMg_JR69g6c"
      },
      "source": [
        "<b>Referencias</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9exzOTk9g6c"
      },
      "source": [
        "https://cloud.ibm.com/apidocs/speech-to-text?code=python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrAzQhHz9g6d"
      },
      "source": [
        "https://cloud.ibm.com/apidocs/language-translator?code=python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_hB-iD9g6d"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8clXYz-9g6d"
      },
      "source": [
        "<h4>Acerca del Autor:</h4>\n",
        "<p><a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> posee un doctorado en Ingeniería Eléctrica. Su trabajo de investigación se centra en el uso de Aprendizaje Automático (Machine Learning), Procesamiento de Señales y Visión Artificial para determinar el impacto de los videos en el proceso cognitivo. Joseph trabaja en IBM desde la terminación de su doctorado.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Uk6BRn9g6e"
      },
      "source": [
        "Otros colaboradores: <a href=\"https://www.linkedin.com/in/fanjiang0619/\">Fan Jiang</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1N79LPO9g6e"
      },
      "source": [
        "Copyright &copy; 2019 [cognitiveclass.ai](https:cognitiveclass.ai). This notebook and its source code are released under the terms of the [MIT License](cognitiveclass.ai)."
      ]
    }
  ]
}